"use client";

import {
  Box,
  Typography,
  TextField,
  Button,
  Select,
  MenuItem,
  FormControl,
  InputLabel,
  RadioGroup,
  Radio,
  FormControlLabel,
  Checkbox,
  Table,
  TableBody,
  TableCell,
  TableContainer,
  TableHead,
  TableRow,
  Paper,
  Stack,
  IconButton,
} from "@mui/material";
import { DatePicker } from "@mui/x-date-pickers/DatePicker";
import {useRef, useEffect, useState } from "react";
import SearchIcon from "@mui/icons-material/Search";
import DragIndicatorIcon from "@mui/icons-material/DragIndicator";
import * as faceapi from "face-api.js";
import { useUserStore } from "@/store/user";
import { getClaimsFromToken } from "@/utils/auth"; // Assuming you have a utility function to decode JWT  
import {luuanhnguoidung} from "@/actions/emr_tnguoidung"; 

const CameraComponent = ({
  onCapture,
  capturedImage,
}: {
  onCapture: (img: string) => void;
  capturedImage: string | null;
}) => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [loading, setLoading] = useState(true);
  const [modelsLoaded, setModelsLoaded] = useState(false);

  // Load face-api models
  useEffect(() => {
    const loadModels = async () => {
      try {
        setLoading(true);
        console.log("Loading face-api models...");
        
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri("/models"),
          faceapi.nets.faceRecognitionNet.loadFromUri("/models"),
          faceapi.nets.faceLandmark68Net.loadFromUri("/models")
        ]);
        
        console.log("Models loaded successfully");
        setModelsLoaded(true);
        setLoading(false);
      } catch (error) {
        console.error("Error loading models:", error);
        setLoading(false);
      }
    };
    loadModels();
  }, []);

  // Get camera stream
  useEffect(() => {
    const getCamera = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
          video: { 
            width: { ideal: 640 },
            height: { ideal: 480 }
          } 
        });
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          
          // ƒê·ª£i video s·∫µn s√†ng
          videoRef.current.onloadedmetadata = () => {
            console.log("Video metadata loaded");
          };
        }
      } catch (err) {
        console.error("Camera error:", err);
        alert("Kh√¥ng th·ªÉ truy c·∫≠p camera");
      }
    };
    getCamera();

    // Cleanup camera stream khi component unmount
    return () => {
      if (videoRef.current && videoRef.current.srcObject) {
        const stream = videoRef.current.srcObject as MediaStream;
        stream.getTracks().forEach(track => track.stop());
      }
    };
  }, []);

// V·∫Ω khung nh·∫≠n di·ªán khu√¥n m·∫∑t li√™n t·ª•c
// useEffect(() => {
//   let animationId: number;
//   let isRunning = false;

//   const drawFaceBox = async () => {
//     if (isRunning) return;
//     isRunning = true;

//     try {
//       if (
//         videoRef.current &&
//         canvasRef.current &&
//         modelsLoaded &&
//         videoRef.current.readyState >= 2 &&
//         !videoRef.current.paused &&
//         !videoRef.current.ended &&
//         videoRef.current.videoWidth > 0 &&
//         videoRef.current.videoHeight > 0
//       ) {
//         const video = videoRef.current;
//         const canvas = canvasRef.current;
        
//         // Debug: Log video dimensions
//         console.log("Video dimensions:", {
//           clientWidth: video.clientWidth,
//           clientHeight: video.clientHeight,
//           videoWidth: video.videoWidth,
//           videoHeight: video.videoHeight
//         });
        
//         // ƒê·∫∑t k√≠ch th∆∞·ªõc canvas kh·ªõp v·ªõi video display size
//         const displayWidth = video.clientWidth;
//         const displayHeight = video.clientHeight;
//         const videoWidth = video.videoWidth;
//         const videoHeight = video.videoHeight;
        
//         canvas.width = displayWidth;
//         canvas.height = displayHeight;
        
//         // T√≠nh t·ª∑ l·ªá scale
//         const scaleX = displayWidth / videoWidth;
//         const scaleY = displayHeight / videoHeight;
        
//         console.log("Scale factors:", { scaleX, scaleY });

//         try {
//           // Ph√°t hi·ªán khu√¥n m·∫∑t
//           console.log("Detecting faces...");
//           const detections = await faceapi.detectAllFaces(
//             video,
//             new faceapi.TinyFaceDetectorOptions({
//               inputSize: 416,
//               scoreThreshold: 0.3 // Gi·∫£m threshold ƒë·ªÉ d·ªÖ detect h∆°n
//             })
//           );
          
//           console.log("Detection results:", detections.length, "faces found");

//           const ctx = canvas.getContext("2d");
//           if (ctx) {
//             // X√≥a canvas
//             ctx.clearRect(0, 0, canvas.width, canvas.height);

//             // V·∫Ω background semi-transparent ƒë·ªÉ debug
//             ctx.fillStyle = "rgba(255, 0, 0, 0.1)";
//             ctx.fillRect(0, 0, canvas.width, canvas.height);

//             if (detections && detections.length > 0) {
//               console.log("Drawing", detections.length, "bounding boxes");
              
//               detections.forEach((detection, index) => {
//                 const box = detection.box;
//                 console.log(`Face ${index + 1} box:`, box);
                
//                 // Scale coordinates
//                 const x = box.x * scaleX;
//                 const y = box.y * scaleY;
//                 const width = box.width * scaleX;
//                 const height = box.height * scaleY;
                
//                 console.log(`Scaled coordinates:`, { x, y, width, height });
                
//                 // V·∫Ω khung ch·ªØ nh·∫≠t v·ªõi m√†u n·ªïi b·∫≠t
//                 ctx.strokeStyle = "#00ff00";
//                 ctx.lineWidth = 4;
//                 ctx.strokeRect(x, y, width, height);
                
//                 // V·∫Ω background cho text
//                 ctx.fillStyle = "rgba(0, 255, 0, 0.8)";
//                 ctx.fillRect(x, y - 25, 120, 25);
                
//                 // V·∫Ω text
//                 const confidence = Math.round(detection.score * 100);
//                 ctx.fillStyle = "#000000";
//                 ctx.font = "14px Arial";
//                 ctx.fillText(
//                   `Face ${index + 1}: ${confidence}%`,
//                   x + 2,
//                   y - 8
//                 );
                
//                 // V·∫Ω ƒëi·ªÉm gi·ªØa
//                 const centerX = x + width / 2;
//                 const centerY = y + height / 2;
//                 ctx.fillStyle = "#ff0000";
//                 ctx.beginPath();
//                 ctx.arc(centerX, centerY, 5, 0, 2 * Math.PI);
//                 ctx.fill();
                
//                 console.log(`Drew bounding box for face ${index + 1}`);
//               });
//             } else {
//               // V·∫Ω text "No faces detected"
//               ctx.fillStyle = "#ff0000";
//               ctx.font = "16px Arial";
//               ctx.fillText("No faces detected", 10, 30);
//             }
//           }
//         } catch (detectionError) {
//           console.error("Face detection error:", detectionError);
//         }
//       } else {
//         console.log("Conditions not met for detection:", {
//           hasVideo: !!videoRef.current,
//           hasCanvas: !!canvasRef.current,
//           modelsLoaded,
//           readyState: videoRef.current?.readyState,
//           paused: videoRef.current?.paused,
//           ended: videoRef.current?.ended,
//           videoWidth: videoRef.current?.videoWidth,
//           videoHeight: videoRef.current?.videoHeight
//         });
//       }
//     } catch (error) {
//       console.error("Error in drawFaceBox:", error);
//     } finally {
//       isRunning = false;
//       // Ti·∫øp t·ª•c animation loop
//       animationId = requestAnimationFrame(drawFaceBox);
//     }
//   };

//   // B·∫Øt ƒë·∫ßu detection loop
//   if (modelsLoaded && !loading) {
//     console.log("Starting face detection loop");
//     drawFaceBox();
//   }

//   return () => {
//     if (animationId) {
//       cancelAnimationFrame(animationId);
//     }
//   };
// }, [modelsLoaded, loading]);

useEffect(() => {
  let intervalId: NodeJS.Timeout;

  const detectFaces = async () => {
    if (
      videoRef.current &&
      canvasRef.current &&
      modelsLoaded &&
      videoRef.current.readyState >= 2
    ) {
      try {
        const video = videoRef.current;
        const canvas = canvasRef.current;
        const ctx = canvas.getContext("2d");
        
        if (!ctx) return;

        // Set canvas size
        canvas.width = video.clientWidth;
        canvas.height = video.clientHeight;

        // Detect faces
        const detections = await faceapi.detectAllFaces(
          video,
          new faceapi.TinyFaceDetectorOptions({
            inputSize: 320,
            scoreThreshold: 0.3
          })
        );

        // Clear canvas
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        // Draw detections
        if (detections.length > 0) {
          const scaleX = canvas.width / video.videoWidth;
          const scaleY = canvas.height / video.videoHeight;

          detections.forEach((detection, i) => {
            const { x, y, width, height } = detection.box;
            
            ctx.strokeStyle = '#00ff00';
            ctx.lineWidth = 3;
            ctx.strokeRect(
              x * scaleX,
              y * scaleY,
              width * scaleX,
              height * scaleY
            );
            
            ctx.fillStyle = '#00ff00';
            ctx.font = '16px Arial';
            ctx.fillText(
              `Face ${i + 1}`,
              x * scaleX,
              y * scaleY - 5
            );
          });
          
          //console.log(`Detected ${detections.length} faces`);
        }
      } catch (error) {
        //console.error("Detection error:", error);
      }
    }
  };

  if (modelsLoaded && !loading) {
    // S·ª≠ d·ª•ng setInterval thay v√¨ requestAnimationFrame
    intervalId = setInterval(detectFaces, 100); // 10 FPS
  }

  return () => {
    if (intervalId) {
      clearInterval(intervalId);
    }
  };
}, [modelsLoaded, loading]);

  // Ch·ª•p h√¨nh v√† nh·∫≠n di·ªán khu√¥n m·∫∑t
  const handleCapture = async () => {
    if (!videoRef.current || !modelsLoaded) {
      alert("Camera ho·∫∑c models ch∆∞a s·∫µn s√†ng!");
      return;
    }

    try {
      const video = videoRef.current;
      const canvas = document.createElement("canvas");
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext("2d");
      
      if (!ctx) {
        alert("Kh√¥ng th·ªÉ t·∫°o canvas context!");
        return;
      }

      // V·∫Ω video frame l√™n canvas
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const imgData = canvas.toDataURL("image/jpeg", 0.9);

      // Ki·ªÉm tra ph√°t hi·ªán khu√¥n m·∫∑t tr∆∞·ªõc khi ch·ª•p
      const detections = await faceapi.detectAllFaces(
        canvas,
        new faceapi.TinyFaceDetectorOptions({
          inputSize: 416,
          scoreThreshold: 0.5
        })
      );

      if (detections.length === 0) {
        alert("Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh! Vui l√≤ng th·ª≠ l·∫°i.");
        return;
      }

      console.log(`Captured image with ${detections.length} face(s) detected`);
      
      // G·ª≠i imgData l√™n backend ƒë·ªÉ so s√°nh v·ªõi CSDL nh√¢n vi√™n
      onCapture(imgData);
    } catch (error) {
      console.error("Error capturing image:", error);
      if (error instanceof Error) {
        alert("L·ªói khi ch·ª•p ·∫£nh: " + error.message);
      } else {
        alert("L·ªói khi ch·ª•p ·∫£nh: " + String(error));
      }
    }
  };

  return (
    <Box sx={{ position: "relative", width: 500, maxWidth: "100%" }}>
      <Box sx={{ position: "relative", borderRadius: 2, overflow: "hidden" }}>
        <video
          ref={videoRef}
          autoPlay
          playsInline
          muted
          style={{ 
            width: "100%", 
            maxWidth: 500, 
            borderRadius: 8,
            display: "block"
          }}
        />
        <canvas
          ref={canvasRef}
          style={{
            position: "absolute",
            top: 0,
            left: 0,
            width: "100%",
            height: "100%",
            pointerEvents: "none",
            borderRadius: 8
          }}
        />
      </Box>
      
      {/* Status indicators */}
      <Box sx={{ mt: 1, mb: 2 }}>
        <Typography variant="caption" color={modelsLoaded ? "success.main" : "warning.main"}>
          {loading ? "üîÑ ƒêang t·∫£i models..." : modelsLoaded ? "‚úÖ Models s·∫µn s√†ng" : "‚ùå L·ªói t·∫£i models"}
        </Typography>
      </Box>

      <Button
        variant="contained"
        sx={{ mt: 1 }}
        onClick={handleCapture}
        disabled={loading || !modelsLoaded}
        fullWidth
      >
        {loading ? "ƒêang t·∫£i m√¥ h√¨nh..." : "üì∏ Ch·ª•p & Nh·∫≠n di·ªán"}
      </Button>
    </Box>
  );
};

export default function staffdetectPage() {
  const [fromDate, setFromDate] = useState(null);
  const [toDate, setToDate] = useState(null);
  const [ctaikhoan, setCtaikhoan] = useState("");
  const [choten, setChoten] = useState("");
  const [capturedImage, setCapturedImage] = useState<string | null>(null);
  const [serverImage, setServerImage] = useState<string | null>(null);
  const { data: loginedUser, setUserData} = useUserStore();  
  const [token, setToken] = useState<string | null>(null);
  const [recognitionTime, setRecognitionTime] = useState<string | null>(null);
  const [isRecognizing, setIsRecognizing] = useState(false);
   useEffect(() => {
        // if (!loginedUser || !loginedUser.ctaikhoan) {
        //   router.push("/login"); // <-- Chuy·ªÉn h∆∞·ªõng n·∫øu ch∆∞a ƒëƒÉng nh·∫≠p
        //   return;
        // } 
      const getTokenFromClient = () => {
      // C√°ch 1: T·ª´ localStorage n·∫øu b·∫°n l∆∞u token ·ªü ƒë√≥
      const storedToken = localStorage.getItem("authToken");
      
      // C√°ch 2: T·ª´ document.cookie
      const cookieToken = document.cookie
        .split('; ')
        .find(row => row.startsWith('authToken='))
        ?.split('=')[1];
      
      return storedToken || cookieToken || null;
    };

    const clientToken = getTokenFromClient();
    setToken(clientToken);
        const claims = getClaimsFromToken();
        if (claims) {
          setUserData(claims);
          // Log or handle the claims as needed 
          //console.log("User claims:", claims);
          // You can set user claims in a global state or context if needed
        } else {
          console.warn("No valid claims found in token");
        }  
      }, []);

    // H√†m g·ª≠i ·∫£nh l√™n backend ƒë·ªÉ ki·ªÉm tra nh√¢n vi√™n
 const handleFaceCapture = async (imgBase64: string) => {
    const startTime = Date.now();
    const startDate = new Date(startTime);
    
    setIsRecognizing(true);
    setRecognitionTime(null);
    
    console.log("=== B·∫ÆT ƒê·∫¶U NH·∫¨N DI·ªÜN KHU√îN M·∫∂T ===");
    console.log("Th·ªùi gian b·∫Øt ƒë·∫ßu:", startDate.toLocaleString());
    console.log("Timestamp b·∫Øt ƒë·∫ßu:", startTime);
    
    setCapturedImage(imgBase64);
    
    try {
      console.log("üîÑ ƒêang g·ª≠i ·∫£nh l√™n API ƒë·ªÉ nh·∫≠n di·ªán nh√¢n vi√™n...");
      
      const apiStartTime = Date.now();
      console.log("Th·ªùi gian g·ªçi API:", new Date(apiStartTime).toLocaleString());
      
      const res = await fetch("/api/staff-detect", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ token: token, image: imgBase64 }),
      });
      
      const apiEndTime = Date.now();
      const apiDuration = apiEndTime - apiStartTime;
      console.log("‚è±Ô∏è Th·ªùi gian API response:", new Date(apiEndTime).toLocaleString());
      console.log("‚ö° Th·ªùi gian x·ª≠ l√Ω API:", apiDuration + "ms");
      
      const data = await res.json();
      console.log("üìã K·∫øt qu·∫£ nh·∫≠n di·ªán:", data);
      
      if (data.found) {
        setServerImage(data.nhanvien.cimg);
        setCtaikhoan(data.nhanvien.ctaikhoan);
        setChoten(data.nhanvien.choten);
        console.log("‚úÖ Nh·∫≠n di·ªán th√†nh c√¥ng:", data.nhanvien.ctaikhoan + " - " + data.nhanvien.choten);
        
        if (data.confidence) {
          console.log("üéØ ƒê·ªô tin c·∫≠y:", data.confidence + "%");
        }
      } else {
        setChoten("Kh√¥ng t√¨m th·∫•y nh√¢n vi√™n tr√πng kh·ªõp");     
        setServerImage(null);
        console.log("‚ùå Kh√¥ng t√¨m th·∫•y nh√¢n vi√™n tr√πng kh·ªõp");
      }
      
    } catch (error) {
      console.error("üö® L·ªói trong qu√° tr√¨nh nh·∫≠n di·ªán:", error);
      setChoten("L·ªói khi nh·∫≠n di·ªán: " + error.message);     
      setServerImage(null);
    } finally {
      const endTime = Date.now();
      const endDate = new Date(endTime);
      const totalDuration = endTime - startTime;
      
      setIsRecognizing(false);
      setRecognitionTime(`${(totalDuration / 1000).toFixed(2)}s`);
      
      console.log("=== K·∫æT TH√öC NH·∫¨N DI·ªÜN KHU√îN M·∫∂T ===");
      console.log("Th·ªùi gian k·∫øt th√∫c:", endDate.toLocaleString());
      console.log("Timestamp k·∫øt th√∫c:", endTime);
      console.log("‚è∞ T·ªîNG TH·ªúI GIAN NH·∫¨N DI·ªÜN:", totalDuration + "ms");
      console.log("‚è∞ T·ªîNG TH·ªúI GIAN NH·∫¨N DI·ªÜN:", (totalDuration / 1000).toFixed(2) + " gi√¢y");
      
      if (totalDuration < 1000) {
        console.log("üöÄ Hi·ªáu su·∫•t: R·∫•t nhanh");
      } else if (totalDuration < 3000) {
        console.log("‚ö° Hi·ªáu su·∫•t: Nhanh");
      } else if (totalDuration < 5000) {
        console.log("‚è≥ Hi·ªáu su·∫•t: Trung b√¨nh");
      } else {
        console.log("üêå Hi·ªáu su·∫•t: Ch·∫≠m");
      }
      
      console.log("================================================");
    }
  };
  // H√†m g·ª≠i ·∫£nh l√™n server
  const handleSendCapture = async (imgBase64: string) => {
    if (!loginedUser) {
      alert("Ch∆∞a ƒëƒÉng nh·∫≠p!");
      return;
    }
    if (!ctaikhoan.trim() || !choten.trim()) {
      alert("Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß t√†i kho·∫£n v√† h·ªç t√™n!");
      return;
    }
    if (!capturedImage) {
      alert("Ch∆∞a c√≥ ·∫£nh ƒë·ªÉ l∆∞u!");
      return;
    }
    // G·ªçi API ƒë·ªÉ l∆∞u ·∫£nh ng∆∞·ªùi d√πng
    console.log("ƒêang g·ª≠i ·∫£nh l√™n server..." + Date.now()); 
    //console.log("G·ª≠i ·∫£nh l√™n server:", imgBase64);
    const result = await luuanhnguoidung(loginedUser.ctaikhoan, "1", 0, ctaikhoan, choten, imgBase64);
    console.log("K·∫øt qu·∫£ l∆∞u ·∫£nh:", result);
    const arr = result as Array<{ _ID: number}>;

    if (typeof arr === "string" && arr === "Authorization has been denied for this request.") {
      alert("B·∫°n kh√¥ng c√≥ quy·ªÅn th√™m ·∫£nh ng∆∞·ªùi d√πng!");
    } else if (
      Array.isArray(arr) &&
      arr.length > 0 &&
      typeof arr[0]._ID !== "undefined"
    ) {
      alert("Th√™m ·∫£nh ng∆∞·ªùi d√πng th√†nh c√¥ng");
    } else {
      alert("Th√™m ·∫£nh ng∆∞·ªùi d√πng th·∫•t b·∫°i");
    }
   
     
  };
  
  // H√†m load ·∫£nh t·ª´ server
  const handleLoadImage = async () => {
    if (!ctaikhoan.trim()) {
      alert("Vui l√≤ng nh·∫≠p t√†i kho·∫£n!");
      return;
    }
    const result = await luuanhnguoidung(loginedUser.ctaikhoan, "2", 0, ctaikhoan, "", "");

    const arr = result as Array<{ cid: number, ctaikhoan: string, choten: string, cimg: string, cngaytao: string }>;

    if (typeof arr === "string" && arr === "Authorization has been denied for this request.") {
      alert("B·∫°n kh√¥ng c√≥ quy·ªÅn t·∫£i ·∫£nh ng∆∞·ªùi d√πng!");
    } else if (
      Array.isArray(arr) &&
      arr.length > 0  
    ) {
      setServerImage(arr[0].cimg);
      setCtaikhoan(arr[0].ctaikhoan);
      setChoten(arr[0].choten);
    } else {
      setServerImage(null);
      setChoten("");
      alert("Kh√¥ng t√¨m th·∫•y ·∫£nh tr√™n server!");
    }
    
  };

  return (
   <Box p={2} 
    sx={{ 
      minHeight: "100vh", // ƒê·∫£m b·∫£o chi·ªÅu cao ƒë·ªß
      overflow: "auto", // Cho ph√©p scroll n·∫øu c·∫ßn
      pb: 4 // Padding bottom th√™m
    }}>
    <Typography variant="h6" gutterBottom sx={{ color: "#1976d2", fontWeight: "normal", letterSpacing: 1 }}>
     Nh·∫≠n di·ªán Khu√¥n m·∫∑t Nh√¢n vi√™n
    </Typography>
    
    <Box display="flex" gap={2} mb={2}>
      <TextField
        label="T√†i kho·∫£n"
        value={ctaikhoan}
        onChange={(e) => setCtaikhoan(e.target.value)}
        size="small"
        required
      />
      <TextField
        label="H·ªç t√™n"
        value={choten}
        onChange={(e) => setChoten(e.target.value)}
        size="small"
        required
      />
      <Button
        variant="outlined"
        color="secondary"
        onClick={handleLoadImage}
      >
        Load ·∫£nh t·ª´ server
      </Button>
    </Box>
    
    {/* Camera Component */}
    <Box mb={3}>
      <CameraComponent onCapture={handleFaceCapture} capturedImage={capturedImage} />
    </Box>
    
    {/* Hi·ªÉn th·ªã tr·∫°ng th√°i nh·∫≠n di·ªán */}
    {isRecognizing && (
      <Box sx={{ mb: 2, p: 1, backgroundColor: "#fff3cd", borderRadius: 1 }}>
        <Typography color="warning.main">
          üîÑ ƒêang nh·∫≠n di·ªán... Vui l√≤ng ch·ªù
        </Typography>
      </Box>
    )}
    
    {recognitionTime && (
      <Box sx={{ mb: 2, p: 1, backgroundColor: "#d1ecf1", borderRadius: 1 }}>
        <Typography color="info.main">
          ‚è±Ô∏è Th·ªùi gian nh·∫≠n di·ªán: {recognitionTime}
        </Typography>
      </Box>
    )}
    
    {/* Container cho ·∫£nh - s·ª≠ d·ª•ng layout responsive */}
    <Box 
      sx={{
        display: "flex",
        flexDirection: { xs: "column", md: "row" }, // Vertical tr√™n mobile, horizontal tr√™n desktop
        gap: 3,
        mt: 3,
        flexWrap: "wrap", // Cho ph√©p wrap xu·ªëng d√≤ng n·∫øu c·∫ßn
        justifyContent: "flex-start",
        alignItems: "flex-start" // Align top ƒë·ªÉ kh√¥ng b·ªã stretch
      }}
    >
      {/* ·∫¢nh v·ª´a ch·ª•p */}
      {capturedImage ? (
        <Box
          sx={{
            p: 2,
            border: "1px solid #ccc",
            borderRadius: 2,
            display: "flex",
            flexDirection: "column",
            alignItems: "center",
            background: "#fafbfc",
            minWidth: { xs: "100%", sm: 320 }, // Full width tr√™n mobile
            maxWidth: { xs: "100%", sm: 400 }, // Gi·ªõi h·∫°n width
            flex: { md: "1" }, // Flexible tr√™n desktop
          }}
        >
          <Typography fontSize={14} mb={1} fontWeight="bold" color="#071b30ff">
            ·∫¢nh v·ª´a ch·ª•p
          </Typography>
          <Box
            sx={{
              width: "100%",
              maxWidth: 300,
              overflow: "hidden",
              borderRadius: 1,
              border: "1px solid #eee"
            }}
          >
            <img
              src={capturedImage}
              alt="·∫¢nh ch·ª•p"
              style={{ 
                width: "100%", 
                height: "auto", 
                display: "block",
                objectFit: "contain" // Gi·ªØ t·ª∑ l·ªá ·∫£nh
              }}
            />
          </Box>
          <Box mt={2} textAlign="center" sx={{ width: "100%" }}>
            <Button
              variant="contained"
              color="primary"
              fullWidth
              onClick={() => {
                if (capturedImage) {
                  handleSendCapture(capturedImage);
                }
              }}
            >
              L∆∞u ·∫£nh
            </Button>
          </Box>
        </Box>
      ) : (
        <Box
          sx={{
            p: 2,
            minWidth: { xs: "100%", sm: 320 },
            minHeight: 280,
            border: "1px dashed #ccc",
            borderRadius: 2,
            background: "#fafbfc",
            display: "flex",
            alignItems: "center",
            justifyContent: "center",
            color: "#bbb",
            flex: { md: "1" },
          }}
        >
          <Typography variant="body2" textAlign="center">
            Ch∆∞a c√≥ ·∫£nh ch·ª•p
          </Typography>
        </Box>
      )}

      {/* ·∫¢nh t·ª´ server */}
      {serverImage ? (
        <Box
          sx={{
            p: 2,
            border: "1px solid #1976d2",
            borderRadius: 2,
            display: "flex",
            flexDirection: "column",
            alignItems: "center",
            background: "#f0f7ff",
            minWidth: { xs: "100%", sm: 320 },
            maxWidth: { xs: "100%", sm: 400 },
            flex: { md: "1" },
          }}
        >
          <Typography fontSize={14} mb={1} fontWeight="bold" color="#071b30ff" textAlign="center">
            Nh√¢n vi√™n: {ctaikhoan} - {choten}
          </Typography>
          <Box
            sx={{
              width: "100%",
              maxWidth: 300,
              overflow: "hidden",
              borderRadius: 1,
              border: "1px solid #eee"
            }}
          >
            <img
              src={serverImage}
              alt="·∫¢nh t·ª´ server"
              style={{ 
                width: "100%", 
                height: "auto", 
                display: "block",
                objectFit: "contain"
              }}
            />
          </Box>
        </Box>
      ) : (
        <Box
          sx={{
            p: 2,
            minWidth: { xs: "100%", sm: 320 },
            minHeight: 280,
            border: "1px dashed #1976d2",
            borderRadius: 2,
            background: "#f0f7ff",
            display: "flex",
            alignItems: "center",
            justifyContent: "center",
            color: "#90caf9",
            flex: { md: "1" },
          }}
        >
          <Typography variant="body2" textAlign="center">
            Kh√¥ng ph√°t hi·ªán ·∫£nh
          </Typography>
        </Box>
      )}
    </Box>
    
    {/* Spacer ƒë·ªÉ ƒë·∫£m b·∫£o c√≥ kho·∫£ng tr·ªëng ph√≠a d∆∞·ªõi */}
    <Box sx={{ height: 50 }} />
  </Box>
  );
}
